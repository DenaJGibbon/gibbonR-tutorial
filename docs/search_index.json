[["index.html", "gibbonR: An R package for the automated detection and classification of female gibbon calls from long-term acoustic recordings Package installation", " gibbonR: An R package for the automated detection and classification of female gibbon calls from long-term acoustic recordings Dena J. Clink 2024-06-10 Package installation You can install the development version from GitHub with: # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;DenaJGibbon/gibbonR&quot;) library(gibbonR) "],["package-summary.html", "Package summary", " Package summary ‘gibbonR’ has functions to: + detect sound events using band-limited energy summation (DetectBLED) + detect and classify sound events using random forest or support vector machine algorithms (gibbonR) + visualize sound events using UMAP plots with affinity propagation lcustering (gibbonID) "],["part-1.-prepare-training-data.html", "1 Part 1. Prepare Training Data 1.1 Download the data from Github 1.2 Part 1A. Training Data with Labeled .wav clips 1.3 Part 1B. Training Data with Raven Selection Tables", " 1 Part 1. Prepare Training Data In ‘gibbonR’ there are two ways that you can format your training data. The first can be a set of labelled .wav clips with the class indicated in the name of the file (e.g., ‘gibbon_01.wav’ and ‘noise_01.wav’). The second is to have a folder of selection tables created in Raven Pro (K. Lisa Yang Center for Conservation Bioacoustics) and a folder with the associated ‘.wav’ files. For the second approach there must be an annotation column indicating the call type and it is assumed that all signals of interest are annotated, and the rest of the files contain only background noise. 1.1 Download the data from Github # You need to tell R where to store the zip files on your computer. destination.file.path.zip &lt;- &quot;/Users/denaclink/Downloads/BorneoExampleData.zip&quot; # You also need to tell R where to save the unzipped files destination.file.path &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/&quot; # This function will download the data from github utils::download.file(&quot;https://github.com/DenaJGibbon/BorneoExampleData/archive/master.zip&quot;, destfile = destination.file.path.zip) # This function will unzip the file utils::unzip(zipfile = destination.file.path.zip, exdir = destination.file.path) # Examine the contents list.of.sound.files &lt;- list.files(paste(destination.file.path, &quot;BorneoExampleData-master&quot;, &quot;data&quot;, sep = &quot;/&quot;), full.names = T) list.of.sound.files Use this function to read in the .RDA file and save it as an R object from https://stackoverflow.com/questions/5577221/how-can-i-load-an-object-into-a-variable-name-that-i-specify-from-an-r-data-file loadRData &lt;- function(fileName) { #loads an RData file, and returns it load(fileName) get(ls()[ls() != &quot;fileName&quot;]) } This function will load the entire list of r data files devtools::load_all(&#39;/Users/denaclink/Desktop/RStudioProjects/gibbonR&#39;) #&gt; ℹ Loading gibbonR # You also need to tell R where to save the unzipped files destination.file.path &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/&quot; # Examine the contents list.of.sound.files &lt;- list.files(paste(destination.file.path, &quot;BorneoExampleData-master&quot;, &quot;data&quot;, sep = &quot;/&quot;), full.names = T) list.of.sound.files #&gt; [1] &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles//BorneoExampleData-master/data/multi.class.training.rda&quot; #&gt; [2] &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles//BorneoExampleData-master/data/S11_20180219_060002_1800sto3600s.rda&quot; list.rda.files &lt;- list() for(x in 1:length(list.of.sound.files)){ list.rda.files[[x]] &lt;- loadRData(list.of.sound.files[[x]]) } Assign each rda an informative name multi.class.list &lt;- list.rda.files[[1]] S11_20180219_060002_1800sto3600s &lt;- list.rda.files[[2]] Now we create a directory with the training .wav files TrainingDataDirectory &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/data/BorneoMultiClass/&quot; # Create if doesn&#39;t already exist dir.create(TrainingDataDirectory,recursive = T) for(a in 1:length(multi.class.list)){ Temp.element &lt;- multi.class.list[[a]] writeWave(Temp.element[[2]], paste(TrainingDataDirectory,Temp.element[[1]],sep=&#39;/&#39;)) } 1.2 Part 1A. Training Data with Labeled .wav clips 1.2.1 Read in clips and calculate MFCCs TrainingDataDirectory &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/data/BorneoMultiClass/&quot; trainingdata &lt;- gibbonR::MFCCFunction(input.dir=TrainingDataDirectory, min.freq = 400, max.freq = 1600,win.avg=&quot;standard&quot;) trainingdata$class &lt;- as.factor(trainingdata$class) 1.2.2 Compare Random Forest and Support Vector Machine for Supervised Classification Note that this approach uses k-fold cross-validation by splitting the training data into two splits over multiple iterations. # Set seed for reproducilibility set.seed(3) # Create an index to randomly sample 25 observations for test data testindex &lt;- sample(1:75,25,replace = FALSE) # Isolate test data samples testdata &lt;- trainingdata[testindex,] # Remove from training data trainingdata_sub &lt;- trainingdata[-testindex,] # Ensure class is a factor trainingdata_sub$class &lt;- as.factor(trainingdata_sub$class) # Run SVM ml.model.svm &lt;- e1071::svm(trainingdata_sub[, 2:ncol(trainingdata_sub)], trainingdata_sub$class, kernel = &quot;radial&quot;, cross = 25, probability = TRUE) # Predict SVM on test data svm.predict.labels &lt;- predict(ml.model.svm,testdata[,-c(1)]) # Create a confusion matrix caret::confusionMatrix(svm.predict.labels,testdata$class) #&gt; Confusion Matrix and Statistics #&gt; #&gt; Reference #&gt; Prediction female.gibbon leaf.monkey noise solo.gibbon #&gt; female.gibbon 7 0 0 0 #&gt; leaf.monkey 0 1 0 0 #&gt; noise 1 1 8 0 #&gt; solo.gibbon 0 0 0 7 #&gt; #&gt; Overall Statistics #&gt; #&gt; Accuracy : 0.92 #&gt; 95% CI : (0.7397, 0.9902) #&gt; No Information Rate : 0.32 #&gt; P-Value [Acc &gt; NIR] : 5.992e-10 #&gt; #&gt; Kappa : 0.8858 #&gt; #&gt; Mcnemar&#39;s Test P-Value : NA #&gt; #&gt; Statistics by Class: #&gt; #&gt; Class: female.gibbon Class: leaf.monkey Class: noise Class: solo.gibbon #&gt; Sensitivity 0.8750 0.5000 1.0000 1.00 #&gt; Specificity 1.0000 1.0000 0.8824 1.00 #&gt; Pos Pred Value 1.0000 1.0000 0.8000 1.00 #&gt; Neg Pred Value 0.9444 0.9583 1.0000 1.00 #&gt; Prevalence 0.3200 0.0800 0.3200 0.28 #&gt; Detection Rate 0.2800 0.0400 0.3200 0.28 #&gt; Detection Prevalence 0.2800 0.0400 0.4000 0.28 #&gt; Balanced Accuracy 0.9375 0.7500 0.9412 1.00 # Run Random Forest ml.model.rf &lt;- randomForest::randomForest(x=trainingdata_sub[, 2:ncol(trainingdata_sub)], y = trainingdata_sub$class) # Predict RF on test data rf.predict.labels &lt;- predict(ml.model.rf,testdata[,-c(1)]) # Create a confusion matrix caret::confusionMatrix(rf.predict.labels,testdata$class) #&gt; Confusion Matrix and Statistics #&gt; #&gt; Reference #&gt; Prediction female.gibbon leaf.monkey noise solo.gibbon #&gt; female.gibbon 7 0 0 0 #&gt; leaf.monkey 0 1 0 1 #&gt; noise 1 1 8 1 #&gt; solo.gibbon 0 0 0 5 #&gt; #&gt; Overall Statistics #&gt; #&gt; Accuracy : 0.84 #&gt; 95% CI : (0.6392, 0.9546) #&gt; No Information Rate : 0.32 #&gt; P-Value [Acc &gt; NIR] : 1.197e-07 #&gt; #&gt; Kappa : 0.7738 #&gt; #&gt; Mcnemar&#39;s Test P-Value : NA #&gt; #&gt; Statistics by Class: #&gt; #&gt; Class: female.gibbon Class: leaf.monkey Class: noise Class: solo.gibbon #&gt; Sensitivity 0.8750 0.5000 1.0000 0.7143 #&gt; Specificity 1.0000 0.9565 0.8235 1.0000 #&gt; Pos Pred Value 1.0000 0.5000 0.7273 1.0000 #&gt; Neg Pred Value 0.9444 0.9565 1.0000 0.9000 #&gt; Prevalence 0.3200 0.0800 0.3200 0.2800 #&gt; Detection Rate 0.2800 0.0400 0.3200 0.2000 #&gt; Detection Prevalence 0.2800 0.0800 0.4400 0.2000 #&gt; Balanced Accuracy 0.9375 0.7283 0.9118 0.8571 1.3 Part 1B. Training Data with Raven Selection Tables 1.3.1 Prepare training data from labeled annotations # Specify the folder where the training data will be saved TrainingDataFolderLocation &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/TrainingDataFromRavenSelectionTables&quot; # Directory with annotated selection tables AnnotatedSelectionTables &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/SelectionTables/GibbonTrainingSelectionTables/&quot;, full.names = T) # Directory with corresponding .wav files AnnotatedWaveFiles &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/GibbonTrainingFiles/&quot;,full.names = T) AnnotatedWaveFilesShort &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/GibbonTrainingFiles/&quot;,full.names = F) AnnotatedWaveFilesShort &lt;- str_split_fixed(AnnotatedWaveFilesShort,pattern = &#39;.wav&#39;, n=2)[,1] # Loop to cut out the corresponding annotations into short clips for(i in 1: length(AnnotatedSelectionTables)){ # Read in selection table TempSelectionTable &lt;- read.delim2(AnnotatedSelectionTables[i]) # Find the corresponding soundfile SoundFileIndex &lt;- which(str_detect(AnnotatedSelectionTables[i],AnnotatedWaveFilesShort)) TempAnnotateWave &lt;- readWave(AnnotatedWaveFiles[SoundFileIndex]) ShortSoundClips &lt;- lapply(1:nrow(TempSelectionTable), function(j) extractWave(TempAnnotateWave, from= as.numeric(TempSelectionTable[j,]$Begin.Time..s.), to=as.numeric(TempSelectionTable[j,]$ End.Time..s.), xunit = c(&quot;time&quot;),plot=F,output=&quot;Wave&quot;)) # Write wave files to folder for(k in 1:length(ShortSoundClips)){ TempClip &lt;- ShortSoundClips[[k]] WavFileName &lt;- paste(TrainingDataFolderLocation,&#39;/female.gibbon_&#39;, k, &#39;.wav&#39;,sep=&quot;&quot;) writeWave(TempClip,WavFileName,extensible = F) } } 1.3.2 Prepare noise training data from files without target signal # Specify the folder where the training data will be saved TrainingDataFolderLocation &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/TrainingDataFromRavenSelectionTables/&quot; # Directory with annotated selection tables NoiseSelectionTables &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/SelectionTables/NoiseSelectionTables/&quot;, full.names = T) # Directory with corresponding .wav files NoiseWaveFiles &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/NoiseFiles/&quot;,full.names = T) NoiseWaveFilesShort &lt;- list.files(&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/NoiseFiles/&quot;,full.names = F) NoiseWaveFilesShort &lt;- str_split_fixed(NoiseWaveFilesShort,pattern = &#39;.wav&#39;, n=2)[,1] for(i in 1:length(NoiseSelectionTables)){ # Find the corresponding soundfile SoundFileIndex &lt;- which(str_detect(NoiseSelectionTables[i],NoiseWaveFilesShort)) DetectBLED(input=NoiseWaveFiles[SoundFileIndex], min.freq = 400, max.freq = 1600, noise.quantile.val=0.3, spectrogram.window =512, pattern.split = &quot;.wav&quot;, min.signal.dur = 3, max.sound.event.dur = 12, wav.output = &quot;TRUE&quot;, output.dir = TrainingDataFolderLocation, swift.time=TRUE, time.start=06, time.stop=11, write.table.output=TRUE, verbose=TRUE, random.sample=FALSE) } 1.3.3 Now read in clips based on Raven Selection tables and calculate MFCCs TrainingWavFilesDir &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/TrainingDataFromRavenSelectionTables/&quot; trainingdata &lt;- gibbonR::MFCCFunction(input.dir=TrainingWavFilesDir, min.freq = 400, max.freq = 1600,win.avg=&quot;standard&quot;) trainingdata$class &lt;- as.factor(trainingdata$class) 1.3.4 Compare Random Forest and Support Vector Machine for Supervised Classification # Set seed for reproducilibility set.seed(3) # Check the structure (this is binary with only two classes) table(trainingdata$class) #&gt; #&gt; female.gibbon noise #&gt; 26 27 # Create an index to randomly sample 25 observations for test data testindex &lt;- sample(1:53,25,replace = FALSE) # Isolate test data samples testdata &lt;- trainingdata[testindex,] # Remove from training data trainingdata_sub &lt;- trainingdata[-testindex,] # Ensure class is a factor trainingdata_sub$class &lt;- as.factor(trainingdata_sub$class) # Run SVM ml.model.svm &lt;- e1071::svm(trainingdata_sub[, 2:ncol(trainingdata_sub)], trainingdata_sub$class, kernel = &quot;radial&quot;, cross = 25, probability = TRUE) # Predict SVM on test data svm.predict.labels &lt;- predict(ml.model.svm,testdata[,-c(1)]) # Create a confusion matrix caret::confusionMatrix(svm.predict.labels,testdata$class) #&gt; Confusion Matrix and Statistics #&gt; #&gt; Reference #&gt; Prediction female.gibbon noise #&gt; female.gibbon 11 0 #&gt; noise 0 14 #&gt; #&gt; Accuracy : 1 #&gt; 95% CI : (0.8628, 1) #&gt; No Information Rate : 0.56 #&gt; P-Value [Acc &gt; NIR] : 5.066e-07 #&gt; #&gt; Kappa : 1 #&gt; #&gt; Mcnemar&#39;s Test P-Value : NA #&gt; #&gt; Sensitivity : 1.00 #&gt; Specificity : 1.00 #&gt; Pos Pred Value : 1.00 #&gt; Neg Pred Value : 1.00 #&gt; Prevalence : 0.44 #&gt; Detection Rate : 0.44 #&gt; Detection Prevalence : 0.44 #&gt; Balanced Accuracy : 1.00 #&gt; #&gt; &#39;Positive&#39; Class : female.gibbon #&gt; # Run Random Forest ml.model.rf &lt;- randomForest::randomForest(x=trainingdata_sub[, 2:ncol(trainingdata_sub)], y = trainingdata_sub$class) # Predict RF on test data rf.predict.labels &lt;- predict(ml.model.rf,testdata[,-c(1)]) # Create a confusion matrix caret::confusionMatrix(rf.predict.labels,testdata$class) #&gt; Confusion Matrix and Statistics #&gt; #&gt; Reference #&gt; Prediction female.gibbon noise #&gt; female.gibbon 11 3 #&gt; noise 0 11 #&gt; #&gt; Accuracy : 0.88 #&gt; 95% CI : (0.6878, 0.9745) #&gt; No Information Rate : 0.56 #&gt; P-Value [Acc &gt; NIR] : 0.0006695 #&gt; #&gt; Kappa : 0.7634 #&gt; #&gt; Mcnemar&#39;s Test P-Value : 0.2482131 #&gt; #&gt; Sensitivity : 1.0000 #&gt; Specificity : 0.7857 #&gt; Pos Pred Value : 0.7857 #&gt; Neg Pred Value : 1.0000 #&gt; Prevalence : 0.4400 #&gt; Detection Rate : 0.4400 #&gt; Detection Prevalence : 0.5600 #&gt; Balanced Accuracy : 0.8929 #&gt; #&gt; &#39;Positive&#39; Class : female.gibbon #&gt; "],["part-2.-run-the-detectorclassifier.html", "2 Part 2. Run the detector/classifier 2.1 Part 2a. Feature extraction 2.2 Part 2b. Run the detector/classifier using the ‘gibbonR’ function.", " 2 Part 2. Run the detector/classifier 2.1 Part 2a. Feature extraction # Specify the folder where the training data will be saved TrainingDataFolderLocation &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/TrainingDataFromRavenSelectionTables/&quot; TrainingDataMFCC &lt;- MFCCFunction(input.dir= TrainingDataFolderLocation, min.freq = 400, max.freq = 1600,win.avg=&quot;standard&quot;) #&gt; [1] &quot;processing sound event 1 out of 53&quot; #&gt; [1] &quot;processing sound event 2 out of 53&quot; #&gt; [1] &quot;processing sound event 3 out of 53&quot; #&gt; [1] &quot;processing sound event 4 out of 53&quot; #&gt; [1] &quot;processing sound event 5 out of 53&quot; #&gt; [1] &quot;processing sound event 6 out of 53&quot; #&gt; [1] &quot;processing sound event 7 out of 53&quot; #&gt; [1] &quot;processing sound event 8 out of 53&quot; #&gt; [1] &quot;processing sound event 9 out of 53&quot; #&gt; [1] &quot;processing sound event 10 out of 53&quot; #&gt; [1] &quot;processing sound event 11 out of 53&quot; #&gt; [1] &quot;processing sound event 12 out of 53&quot; #&gt; [1] &quot;processing sound event 13 out of 53&quot; #&gt; [1] &quot;processing sound event 14 out of 53&quot; #&gt; [1] &quot;processing sound event 15 out of 53&quot; #&gt; [1] &quot;processing sound event 16 out of 53&quot; #&gt; [1] &quot;processing sound event 17 out of 53&quot; #&gt; [1] &quot;processing sound event 18 out of 53&quot; #&gt; [1] &quot;processing sound event 19 out of 53&quot; #&gt; [1] &quot;processing sound event 20 out of 53&quot; #&gt; [1] &quot;processing sound event 21 out of 53&quot; #&gt; [1] &quot;processing sound event 22 out of 53&quot; #&gt; [1] &quot;processing sound event 23 out of 53&quot; #&gt; [1] &quot;processing sound event 24 out of 53&quot; #&gt; [1] &quot;processing sound event 25 out of 53&quot; #&gt; [1] &quot;processing sound event 26 out of 53&quot; #&gt; [1] &quot;processing sound event 27 out of 53&quot; #&gt; [1] &quot;processing sound event 28 out of 53&quot; #&gt; [1] &quot;processing sound event 29 out of 53&quot; #&gt; [1] &quot;processing sound event 30 out of 53&quot; #&gt; [1] &quot;processing sound event 31 out of 53&quot; #&gt; [1] &quot;processing sound event 32 out of 53&quot; #&gt; [1] &quot;processing sound event 33 out of 53&quot; #&gt; [1] &quot;processing sound event 34 out of 53&quot; #&gt; [1] &quot;processing sound event 35 out of 53&quot; #&gt; [1] &quot;processing sound event 36 out of 53&quot; #&gt; [1] &quot;processing sound event 37 out of 53&quot; #&gt; [1] &quot;processing sound event 38 out of 53&quot; #&gt; [1] &quot;processing sound event 39 out of 53&quot; #&gt; [1] &quot;processing sound event 40 out of 53&quot; #&gt; [1] &quot;processing sound event 41 out of 53&quot; #&gt; [1] &quot;processing sound event 42 out of 53&quot; #&gt; [1] &quot;processing sound event 43 out of 53&quot; #&gt; [1] &quot;processing sound event 44 out of 53&quot; #&gt; [1] &quot;processing sound event 45 out of 53&quot; #&gt; [1] &quot;processing sound event 46 out of 53&quot; #&gt; [1] &quot;processing sound event 47 out of 53&quot; #&gt; [1] &quot;processing sound event 48 out of 53&quot; #&gt; [1] &quot;processing sound event 49 out of 53&quot; #&gt; [1] &quot;processing sound event 50 out of 53&quot; #&gt; [1] &quot;processing sound event 51 out of 53&quot; #&gt; [1] &quot;processing sound event 52 out of 53&quot; #&gt; [1] &quot;processing sound event 53 out of 53&quot; TrainingDataMFCC$class &lt;- as.factor(TrainingDataMFCC$class) 2.2 Part 2b. Run the detector/classifier using the ‘gibbonR’ function. TestFileDirectory &lt;- &#39;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/GibbonTestFiles/&#39; OutputDirectory &lt;- &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/DetectAndClassifyOutput&quot; dir.create(OutputDirectory,recursive = TRUE) #&gt; Warning in dir.create(OutputDirectory, recursive = TRUE): #&gt; &#39;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/DetectAndClassifyOutput&#39; already #&gt; exists gibbonR(input=TestFileDirectory, input.type = &#39;directory&#39;, feature.df=TrainingDataMFCC, model.type.list=c(&#39;SVM&#39;,&#39;RF&#39;), tune = TRUE, short.wav.duration=300, target.signal = c(&quot;female.gibbon&quot;), min.freq = 400, max.freq = 1600, noise.quantile.val=0.15, minimum.separation =3, n.windows = 9, num.cep = 12, spectrogram.window =160, pattern.split = &quot;.wav&quot;, min.signal.dur = 3, max.sound.event.dur = 25, maximum.separation =1, probability.thresh.svm = 0.15, probability.thresh.rf = 0.15, wav.output = &quot;FALSE&quot;, output.dir =OutputDirectory, swift.time=TRUE,time.start=5,time.stop=10, write.table.output=TRUE,verbose=TRUE, random.sample=&#39;NA&#39;) #&gt; [1] &quot;Machine learning in progress...&quot; #&gt; [1] &quot;SVM in progress...&quot; #&gt; [1] &quot;SVM accuracy 98.1132075471698&quot; #&gt; Time difference of 1.382857 secs #&gt; [1] &quot;RF in progress...&quot; #&gt; #&gt; Call: #&gt; randomForest(x = feature.df[, 2:ncol(feature.df)], y = feature.df$class) #&gt; Type of random forest: classification #&gt; Number of trees: 500 #&gt; No. of variables tried at each split: 13 #&gt; #&gt; OOB estimate of error rate: 9.43% #&gt; Confusion matrix: #&gt; female.gibbon noise class.error #&gt; female.gibbon 23 3 0.11538462 #&gt; noise 2 25 0.07407407 #&gt; Time difference of 0.05543208 secs #&gt; [1] &quot;Classifying for target signal female.gibbon&quot; #&gt; [1] &quot;Computing spectrogram for file S11_20180217_080003 1 out of 1&quot; #&gt; [1] &quot;Running detector over sound files&quot; #&gt; [1] &quot;Creating datasheet&quot; #&gt; [1] &quot;Saving Sound Files S11_20180217_080003 1 out of 1&quot; #&gt; [1] &quot;System processed 7201 seconds in 12 seconds this translates to 576.8 hours processed in 1 hour&quot; # Load necessary libraries library(stringr) # For string manipulation library(caret) # For machine learning and model evaluation library(ggpubr) # For data visualization library(dplyr) # For data manipulation library(data.table) # For sorting the detections library(ggplot2) # NOTE you need to change the file paths below to where your files are located on your computer # KSWS Performance Binary -------------------------------------------------------- # Get a list of TopModel result files TopModelresults &lt;- list.files(&#39;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/DetectAndClassifyOutput&#39;, full.names = TRUE) # Get a list of annotation selection table files TestDataSet &lt;- list.files(&#39;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/SelectionTables/GibbonTestSelectionTables&#39;, full.names = TRUE) start.time.buffer &lt;- 12 end.time.buffer &lt;- 12 # Preallocate space for TopModelDetectionDF TopModelDetectionDF &lt;- data.frame() # Loop through each TopModel result file for (f in 1:length(TopModelresults)) { # Read the TopModel result table into a data frame TempTopModelTable &lt;- read.delim2(TopModelresults[f]) # Extract the short name of the TopModel result file ShortName &lt;- basename(TopModelresults[f]) ShortName &lt;- str_split_fixed(ShortName, pattern = &#39;gibbonR&#39;, n = 2)[, 1] # Find the corresponding annotation selection table testDataIndex &lt;- which(str_detect(TestDataSet, ShortName)) if(length(testDataIndex) &gt; 0 ){ TestDataTable &lt;- read.delim2(TestDataSet[testDataIndex]) # Round Begin.Time..s. and End.Time..s. columns to numeric TestDataTable$Begin.Time..s. &lt;- round(as.numeric(TestDataTable$Begin.Time..s.)) TestDataTable$End.Time..s. &lt;- round(as.numeric(TestDataTable$End.Time..s.)) DetectionList &lt;- list() # Loop through each row in TempTopModelTable for (c in 1:nrow(TempTopModelTable)) { TempRow &lt;- TempTopModelTable[c,] # Check if Begin.Time..s. is not NA if (!is.na(TempRow$Begin.Time..s.)) { # Convert Begin.Time..s. and End.Time..s. to numeric TempRow$Begin.Time..s. &lt;- as.numeric(TempRow$Begin.Time..s.) TempRow$End.Time..s. &lt;- as.numeric(TempRow$End.Time..s.) # Determine if the time of the detection is within the time range of an annotation TimeBetween &lt;- data.table::between(TempRow$Begin.Time..s., TestDataTable$Begin.Time..s. - start.time.buffer, TestDataTable$End.Time..s. + end.time.buffer) # Extract the detections matching the time range matched_detections &lt;- TestDataTable[TimeBetween, ] if (nrow(matched_detections) &gt; 0) { # Set signal based on the Call.Type in matched_detections TempRow$signal &lt;- &#39;Gibbon&#39; DetectionList[[length( unlist(DetectionList))+1]] &lt;- which(TimeBetween == TRUE) } else { # Set signal to &#39;Noise&#39; if no corresponding annotation is found TempRow$signal &lt;- &#39;noise&#39; } # Append TempRow to TopModelDetectionDF TopModelDetectionDF &lt;- rbind.data.frame(TopModelDetectionDF, TempRow) } } # Identify missed detections if (length( unlist(DetectionList)) &gt; 0 &amp; length( unlist(DetectionList)) &lt; nrow(TestDataTable) ) { missed_detections &lt;- TestDataTable[-unlist(DetectionList), ] # Prepare missed detections data missed_detections &lt;- missed_detections[, c(&quot;Selection&quot;, &quot;View&quot;, &quot;Channel&quot;, &quot;Begin.Time..s.&quot;, &quot;End.Time..s.&quot;, &quot;Low.Freq..Hz.&quot;, &quot;High.Freq..Hz.&quot;)] missed_detections &lt;- missed_detections missed_detections$File.Name &lt;- ShortName missed_detections$model.type &lt;- &#39;SVM&#39; missed_detections$probability &lt;- 0 missed_detections$signal &lt;- &#39;Gibbon&#39; # Append missed detections to TopModelDetectionDF TopModelDetectionDF &lt;- rbind.data.frame(TopModelDetectionDF, missed_detections) } if (length( unlist(DetectionList)) == 0) { missed_detections &lt;- TestDataTable # Prepare missed detections data missed_detections &lt;- missed_detections missed_detections$File.Name &lt;- ShortName missed_detections$model.type &lt;- &#39;SVM&#39; missed_detections$probability &lt;- 0 missed_detections$signal &lt;- &#39;Gibbon&#39; # Append missed detections to TopModelDetectionDF TopModelDetectionDF &lt;- rbind.data.frame(TopModelDetectionDF, missed_detections) } } } head(TopModelDetectionDF) #&gt; Selection View Channel Begin.Time..s. End.Time..s. Low.Freq..Hz. High.Freq..Hz. #&gt; 1 1 Spectrogram 1 1 15.231 20.911 400 1600 #&gt; 2 2 Spectrogram 1 1 26.191 49.982 400 1600 #&gt; 3 3 Spectrogram 1 1 51.342 56.542 400 1600 #&gt; 4 4 Spectrogram 1 1 92.883 100.613 400 1600 #&gt; 5 5 Spectrogram 1 1 102.303 144.125 400 1600 #&gt; 6 6 Spectrogram 1 1 108.404 119.474 400 1600 #&gt; File.Name model.type probability signal #&gt; 1 S11_20180217_080003 RF 0.192 noise #&gt; 2 S11_20180217_080003 RF 0.472 noise #&gt; 3 S11_20180217_080003 RF 0.44 noise #&gt; 4 S11_20180217_080003 RF 0.414 noise #&gt; 5 S11_20180217_080003 RF 0.7 noise #&gt; 6 S11_20180217_080003 SVM 0.219 noise nrow(TopModelDetectionDF) #&gt; [1] 86 table(TopModelDetectionDF$signal) #&gt; #&gt; Gibbon noise #&gt; 29 57 # Convert signal column to a factor variable TopModelDetectionDF$signal &lt;- as.factor(TopModelDetectionDF$signal) # Display unique values in the signal column unique(TopModelDetectionDF$signal) #&gt; [1] noise Gibbon #&gt; Levels: Gibbon noise # Define a vector of confidence Thresholds Thresholds &lt;-seq(0.1,1,0.1) # Create an empty data frame to store results BestF1data.frameGibbonBinary &lt;- data.frame() # Loop through each threshold value for(a in 1:length(Thresholds)){ # Filter the subset based on the confidence threshold TopModelDetectionDF_single &lt;-TopModelDetectionDF TopModelDetectionDF_single$Predictedsignal &lt;- ifelse(TopModelDetectionDF_single$probability &lt;=Thresholds[a], &#39;noise&#39;,&#39;Gibbon&#39;) # Calculate confusion matrix using caret package caretConf &lt;- caret::confusionMatrix( as.factor(TopModelDetectionDF_single$Predictedsignal), as.factor(TopModelDetectionDF_single$signal),positive = &#39;Gibbon&#39;, mode = &#39;everything&#39;) # Extract F1 score, Precision, and Recall from the confusion matrix F1 &lt;- caretConf$byClass[7] Precision &lt;- caretConf$byClass[5] Recall &lt;- caretConf$byClass[6] FP &lt;- caretConf$table[1,2] TN &lt;- sum(caretConf$table[2,])#+JahooAdj FPR &lt;- FP / (FP + TN) # Create a row for the result and add it to the BestF1data.frameGreyGibbon #TrainingData &lt;- training_data_type TempF1Row &lt;- cbind.data.frame(F1, Precision, Recall,FPR) TempF1Row$Thresholds &lt;- Thresholds[a] BestF1data.frameGibbonBinary &lt;- rbind.data.frame(BestF1data.frameGibbonBinary, TempF1Row) } #&gt; Warning in confusionMatrix.default(as.factor(TopModelDetectionDF_single$Predictedsignal), : Levels are #&gt; not in the same order for reference and data. Refactoring data to match. #&gt; Warning in confusionMatrix.default(as.factor(TopModelDetectionDF_single$Predictedsignal), : Levels are #&gt; not in the same order for reference and data. Refactoring data to match. BestF1data.frameGibbonBinary #&gt; F1 Precision Recall FPR Thresholds #&gt; F1 0.5043478 0.3372093 1.00000000 1.00000000 0.1 #&gt; F11 0.6000000 0.4426230 0.93103448 0.57627119 0.2 #&gt; F12 0.6478873 0.5476190 0.79310345 0.30158730 0.3 #&gt; F13 0.6071429 0.6296296 0.58620690 0.14492754 0.4 #&gt; F14 0.6086957 0.8235294 0.48275862 0.04166667 0.5 #&gt; F15 0.5714286 0.9230769 0.41379310 0.01351351 0.6 #&gt; F16 0.5128205 1.0000000 0.34482759 0.00000000 0.7 #&gt; F17 0.3428571 1.0000000 0.20689655 0.00000000 0.8 #&gt; F18 0.1290323 1.0000000 0.06896552 0.00000000 0.9 #&gt; F19 NA NA 0.00000000 0.00000000 1.0 GibbonMax &lt;- round(max(na.omit(BestF1data.frameGibbonBinary$F1)),2) # Metric plot GibbonBinaryPlot &lt;- ggplot(data = BestF1data.frameGibbonBinary, aes(x = Thresholds)) + geom_line(aes(y = F1, color = &quot;F1&quot;, linetype = &quot;F1&quot;)) + geom_line(aes(y = Precision, color = &quot;Precision&quot;, linetype = &quot;Precision&quot;)) + geom_line(aes(y = Recall, color = &quot;Recall&quot;, linetype = &quot;Recall&quot;)) + labs(title = paste(&quot;Gibbon automated detection (binary) \\n max F1:&quot;,GibbonMax), x = &quot;Confidence&quot;, y = &quot;Values&quot;) + scale_color_manual(values = c(&quot;F1&quot; = &quot;blue&quot;, &quot;Precision&quot; = &quot;red&quot;, &quot;Recall&quot; = &quot;green&quot;), labels = c(&quot;F1&quot;, &quot;Precision&quot;, &quot;Recall&quot;)) + scale_linetype_manual(values = c(&quot;F1&quot; = &quot;dashed&quot;, &quot;Precision&quot; = &quot;dotted&quot;, &quot;Recall&quot; = &quot;solid&quot;)) + theme_minimal() + theme(legend.title = element_blank())+ labs(color = &quot;Guide name&quot;, linetype = &quot;Guide name&quot;, shape = &quot;Guide name&quot;) GibbonBinaryPlot #&gt; Warning: Removed 1 row containing missing values or values outside the scale range (`geom_line()`). #&gt; Warning: Removed 1 row containing missing values or values outside the scale range (`geom_line()`). "],["part-4.-data-visualization.html", "3 Part 4. Data visualization 3.1 Part 4a. Create a UMAP plot colored by class 3.2 Part 4b. Create a UMAP plot colored by affinity propagation clustering", " 3 Part 4. Data visualization 3.1 Part 4a. Create a UMAP plot colored by class devtools::load_all(&#39;/Users/denaclink/Desktop/RStudioProjects/gibbonR&#39;) #&gt; ℹ Loading gibbonR library(ggpubr) library(apcluster) gibbonID(input.dir=&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClasses&quot;,output.dir=&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClassesThumbnails/&quot;,win.avg=&#39;standard&#39;,add.spectrograms=TRUE,min.freq=400,max.freq=1600,class=&#39;no.clustering&#39;) #&gt; [1] &quot;Step 1 Calculating MFCCs&quot; #&gt; [1] &quot;processing sound event 1 out of 75&quot; #&gt; [1] &quot;processing sound event 2 out of 75&quot; #&gt; [1] &quot;processing sound event 3 out of 75&quot; #&gt; [1] &quot;processing sound event 4 out of 75&quot; #&gt; [1] &quot;processing sound event 5 out of 75&quot; #&gt; [1] &quot;processing sound event 6 out of 75&quot; #&gt; [1] &quot;processing sound event 7 out of 75&quot; #&gt; [1] &quot;processing sound event 8 out of 75&quot; #&gt; [1] &quot;processing sound event 9 out of 75&quot; #&gt; [1] &quot;processing sound event 10 out of 75&quot; #&gt; [1] &quot;processing sound event 11 out of 75&quot; #&gt; [1] &quot;processing sound event 12 out of 75&quot; #&gt; [1] &quot;processing sound event 13 out of 75&quot; #&gt; [1] &quot;processing sound event 14 out of 75&quot; #&gt; [1] &quot;processing sound event 15 out of 75&quot; #&gt; [1] &quot;processing sound event 16 out of 75&quot; #&gt; [1] &quot;processing sound event 17 out of 75&quot; #&gt; [1] &quot;processing sound event 18 out of 75&quot; #&gt; [1] &quot;processing sound event 19 out of 75&quot; #&gt; [1] &quot;processing sound event 20 out of 75&quot; #&gt; [1] &quot;processing sound event 21 out of 75&quot; #&gt; [1] &quot;processing sound event 22 out of 75&quot; #&gt; [1] &quot;processing sound event 23 out of 75&quot; #&gt; [1] &quot;processing sound event 24 out of 75&quot; #&gt; [1] &quot;processing sound event 25 out of 75&quot; #&gt; [1] &quot;processing sound event 26 out of 75&quot; #&gt; [1] &quot;processing sound event 27 out of 75&quot; #&gt; [1] &quot;processing sound event 28 out of 75&quot; #&gt; [1] &quot;processing sound event 29 out of 75&quot; #&gt; [1] &quot;processing sound event 30 out of 75&quot; #&gt; [1] &quot;processing sound event 31 out of 75&quot; #&gt; [1] &quot;processing sound event 32 out of 75&quot; #&gt; [1] &quot;processing sound event 33 out of 75&quot; #&gt; [1] &quot;processing sound event 34 out of 75&quot; #&gt; [1] &quot;processing sound event 35 out of 75&quot; #&gt; [1] &quot;processing sound event 36 out of 75&quot; #&gt; [1] &quot;processing sound event 37 out of 75&quot; #&gt; [1] &quot;processing sound event 38 out of 75&quot; #&gt; [1] &quot;processing sound event 39 out of 75&quot; #&gt; [1] &quot;processing sound event 40 out of 75&quot; #&gt; [1] &quot;processing sound event 41 out of 75&quot; #&gt; [1] &quot;processing sound event 42 out of 75&quot; #&gt; [1] &quot;processing sound event 43 out of 75&quot; #&gt; [1] &quot;processing sound event 44 out of 75&quot; #&gt; [1] &quot;processing sound event 45 out of 75&quot; #&gt; [1] &quot;processing sound event 46 out of 75&quot; #&gt; [1] &quot;processing sound event 47 out of 75&quot; #&gt; [1] &quot;processing sound event 48 out of 75&quot; #&gt; [1] &quot;processing sound event 49 out of 75&quot; #&gt; [1] &quot;processing sound event 50 out of 75&quot; #&gt; [1] &quot;processing sound event 51 out of 75&quot; #&gt; [1] &quot;processing sound event 52 out of 75&quot; #&gt; [1] &quot;processing sound event 53 out of 75&quot; #&gt; [1] &quot;processing sound event 54 out of 75&quot; #&gt; [1] &quot;processing sound event 55 out of 75&quot; #&gt; [1] &quot;processing sound event 56 out of 75&quot; #&gt; [1] &quot;processing sound event 57 out of 75&quot; #&gt; [1] &quot;processing sound event 58 out of 75&quot; #&gt; [1] &quot;processing sound event 59 out of 75&quot; #&gt; [1] &quot;processing sound event 60 out of 75&quot; #&gt; [1] &quot;processing sound event 61 out of 75&quot; #&gt; [1] &quot;processing sound event 62 out of 75&quot; #&gt; [1] &quot;processing sound event 63 out of 75&quot; #&gt; [1] &quot;processing sound event 64 out of 75&quot; #&gt; [1] &quot;processing sound event 65 out of 75&quot; #&gt; [1] &quot;processing sound event 66 out of 75&quot; #&gt; [1] &quot;processing sound event 67 out of 75&quot; #&gt; [1] &quot;processing sound event 68 out of 75&quot; #&gt; [1] &quot;processing sound event 69 out of 75&quot; #&gt; [1] &quot;processing sound event 70 out of 75&quot; #&gt; [1] &quot;processing sound event 71 out of 75&quot; #&gt; [1] &quot;processing sound event 72 out of 75&quot; #&gt; [1] &quot;processing sound event 73 out of 75&quot; #&gt; [1] &quot;processing sound event 74 out of 75&quot; #&gt; [1] &quot;processing sound event 75 out of 75&quot; #&gt; [1] &quot;Step 2 Using class labels for clustering&quot; #&gt; [1] &quot;Step 3 Creating Spectrograms &quot; #&gt; [1] &quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClassesThumbnails/ already exists&quot; #&gt; [1] &quot;Adding Spectrograms to Plot Step 3 of 3&quot; #&gt; [1] &quot;plot saved at /Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClassesThumbnails//DetectionsAffinityPlot.png&quot; 3.2 Part 4b. Create a UMAP plot colored by affinity propagation clustering gibbonID(input.dir=&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClasses&quot;,output.dir=&quot;/Users/denaclink/Library/CloudStorage/Box-Box/gibbonRSampleFiles/MultipleSoundClassesThumbnails/&quot;,win.avg=&#39;standard&#39;,class=&#39;affinity.fixed&#39;, q.fixed=0.1,add.spectrograms=TRUE,min.freq=400,max.freq=1600) "]]
